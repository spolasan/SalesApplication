{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa92d7c7-e73e-4164-b232-f749307cbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get a list of all files in the \"data\" directory\n",
    "files = os.listdir(\"data\")\n",
    "\n",
    "# Create a dictionary where the keys are filenames (without extension) and values are DataFrames\n",
    "data = {\n",
    "    os.path.splitext(file)[0]: pd.read_csv(os.path.join(\"data\", file))\n",
    "    for file in files if file.endswith('.csv')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f6b4dc16-5a46-4ea6-8e37-ee3c80b74ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ameriplex_fuel_sales_updated.csv',\n",
       " 'ameriplex_sales_regenerated.csv',\n",
       " 'cumulative_sales_regenerated.csv',\n",
       " 'fail_road_sales_regenerated.csv',\n",
       " 'rolling_prairie_sales_regenerated.csv',\n",
       " 'winona_sales_regenerated.csv']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "22a24b75-19f4-42fc-9759-9eb0a2fb9656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataframe for ameriplex sales data...\n",
      "Removed 0 duplicate rows in ameriplex.\n",
      "Missing values before imputation for ameriplex:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "Missing values after imputation for ameriplex:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Cleaning dataframe for fail_road sales data...\n",
      "Removed 0 duplicate rows in fail_road.\n",
      "Missing values before imputation for fail_road:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "Missing values after imputation for fail_road:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Cleaning dataframe for rolling_prairie sales data...\n",
      "Removed 0 duplicate rows in rolling_prairie.\n",
      "Missing values before imputation for rolling_prairie:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "Missing values after imputation for rolling_prairie:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Cleaning dataframe for winona sales data...\n",
      "Removed 0 duplicate rows in winona.\n",
      "Missing values before imputation for winona:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "Missing values after imputation for winona:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to clean and prepare the data\n",
    "def clean_and_concatenate_dataframes(*dataframes):\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for location_name, df in dataframes:\n",
    "        print(f\"Cleaning dataframe for {location_name} sales data...\")\n",
    "        \n",
    "        # Convert 'Month' column to datetime if not already\n",
    "        df['Month'] = pd.to_datetime(df['Month'])\n",
    "        \n",
    "        # Ensure 'Sales' column is of integer type\n",
    "        df['Sales'] = df['Sales'].astype(int)\n",
    "        \n",
    "        # Add the location name as a new column\n",
    "        df['Location'] = location_name\n",
    "        \n",
    "        # Remove leading/trailing spaces from text columns (if applicable)\n",
    "        if 'Product Category' in df.columns:\n",
    "            df['Product Category'] = df['Product Category'].str.strip()\n",
    "        \n",
    "        # Check for and remove duplicate rows\n",
    "        original_length = len(df)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        duplicates_removed = original_length - len(df)\n",
    "        print(f\"Removed {duplicates_removed} duplicate rows in {location_name}.\")\n",
    "        \n",
    "        # Count missing values before imputation\n",
    "        missing_before_impute = df.isnull().sum()\n",
    "        print(f\"Missing values before imputation for {location_name}:\\n{missing_before_impute}\")\n",
    "        \n",
    "        # Handle missing values using forward fill, backward fill, or interpolation\n",
    "        # Forward fill: Use previous value to fill NaNs\n",
    "        df['Sales'].ffill(inplace=True)\n",
    "        \n",
    "        # Alternatively, you could use backward fill:\n",
    "        # df['Sales'].bfill(inplace=True)\n",
    "        \n",
    "        # Or use linear interpolation if the missing values are not too sparse\n",
    "        # df['Sales'] = df['Sales'].interpolate(method='linear')\n",
    "        \n",
    "        # Count missing values after imputation\n",
    "        missing_after_impute = df.isnull().sum()\n",
    "        print(f\"Missing values after imputation for {location_name}:\\n{missing_after_impute}\\n\\n\")\n",
    "\n",
    "        # Saving the cleaned dataframes into a directory\n",
    "        df.to_csv(os.path.join(\"cleaned_data\", location_name + \"_cleaned.csv\"))\n",
    "        \n",
    "        cleaned_dfs.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into a single dataframe\n",
    "    product_sales_data = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "    \n",
    "    return product_sales_data\n",
    "\n",
    "# Clean and concatenate the dataframes\n",
    "product_sales_data = clean_and_concatenate_dataframes(\n",
    "    (\"ameriplex\", data[\"ameriplex_sales_regenerated\"]),\n",
    "    (\"fail_road\", data[\"fail_road_sales_regenerated\"]),\n",
    "    (\"rolling_prairie\", data[\"rolling_prairie_sales_regenerated\"]),\n",
    "    (\"winona\", data[\"winona_sales_regenerated\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d4bfd74-64a6-4fe8-acff-f1146cdb94b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Cigarettes</td>\n",
       "      <td>181</td>\n",
       "      <td>ameriplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Other Tobacco</td>\n",
       "      <td>477</td>\n",
       "      <td>ameriplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Beer</td>\n",
       "      <td>125</td>\n",
       "      <td>ameriplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Wine</td>\n",
       "      <td>256</td>\n",
       "      <td>ameriplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Packaged Beverages-nonalcoh</td>\n",
       "      <td>393</td>\n",
       "      <td>ameriplex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Money Transfers</td>\n",
       "      <td>311</td>\n",
       "      <td>winona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>No Scan Merch Radiant</td>\n",
       "      <td>356</td>\n",
       "      <td>winona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Novelty</td>\n",
       "      <td>414</td>\n",
       "      <td>winona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Phone Card Fee</td>\n",
       "      <td>393</td>\n",
       "      <td>winona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Supplies-retail</td>\n",
       "      <td>114</td>\n",
       "      <td>winona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4704 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month             Product Category  Sales   Location\n",
       "0    2022-01-01                   Cigarettes    181  ameriplex\n",
       "1    2022-01-01                Other Tobacco    477  ameriplex\n",
       "2    2022-01-01                         Beer    125  ameriplex\n",
       "3    2022-01-01                         Wine    256  ameriplex\n",
       "4    2022-01-01  Packaged Beverages-nonalcoh    393  ameriplex\n",
       "...         ...                          ...    ...        ...\n",
       "4699 2023-12-01              Money Transfers    311     winona\n",
       "4700 2023-12-01        No Scan Merch Radiant    356     winona\n",
       "4701 2023-12-01                      Novelty    414     winona\n",
       "4702 2023-12-01               Phone Card Fee    393     winona\n",
       "4703 2023-12-01              Supplies-retail    114     winona\n",
       "\n",
       "[4704 rows x 4 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the combined dataframe\n",
    "product_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6a4dc1e-e48d-4e39-978b-96d60110860f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataframe for ameriplex_fuel sales data...\n",
      "Removed 0 duplicate rows in ameriplex_fuel.\n",
      "Missing values before imputation for ameriplex_fuel:\n",
      "Month        0\n",
      "Fuel Type    0\n",
      "Sales        0\n",
      "Location     0\n",
      "dtype: int64\n",
      "Missing values after imputation for ameriplex_fuel:\n",
      "Month        0\n",
      "Fuel Type    0\n",
      "Sales        0\n",
      "Location     0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Cleaning dataframe for cumulative_sales sales data...\n",
      "Removed 0 duplicate rows in cumulative_sales.\n",
      "Missing values before imputation for cumulative_sales:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "Missing values after imputation for cumulative_sales:\n",
      "Month               0\n",
      "Product Category    0\n",
      "Sales               0\n",
      "Location            0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Cigarettes</td>\n",
       "      <td>1016</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Other Tobacco</td>\n",
       "      <td>971</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Beer</td>\n",
       "      <td>1072</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Wine</td>\n",
       "      <td>806</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Packaged Beverages-nonalcoh</td>\n",
       "      <td>1230</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Money Transfers</td>\n",
       "      <td>1138</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>No Scan Merch Radiant</td>\n",
       "      <td>1067</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Novelty</td>\n",
       "      <td>1015</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Phone Card Fee</td>\n",
       "      <td>1330</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>Supplies-retail</td>\n",
       "      <td>884</td>\n",
       "      <td>cumulative_sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month             Product Category  Sales          Location\n",
       "0    2022-01-01                   Cigarettes   1016  cumulative_sales\n",
       "1    2022-01-01                Other Tobacco    971  cumulative_sales\n",
       "2    2022-01-01                         Beer   1072  cumulative_sales\n",
       "3    2022-01-01                         Wine    806  cumulative_sales\n",
       "4    2022-01-01  Packaged Beverages-nonalcoh   1230  cumulative_sales\n",
       "...         ...                          ...    ...               ...\n",
       "1171 2023-12-01              Money Transfers   1138  cumulative_sales\n",
       "1172 2023-12-01        No Scan Merch Radiant   1067  cumulative_sales\n",
       "1173 2023-12-01                      Novelty   1015  cumulative_sales\n",
       "1174 2023-12-01               Phone Card Fee   1330  cumulative_sales\n",
       "1175 2023-12-01              Supplies-retail    884  cumulative_sales\n",
       "\n",
       "[1176 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_concatenate_dataframes(\n",
    "    (\"ameriplex_fuel\", data[\"ameriplex_fuel_sales_updated\"]))\n",
    "clean_and_concatenate_dataframes(\n",
    "    (\"cumulative_sales\", data[\"cumulative_sales_regenerated\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c320c-9d74-4e6f-9432-d6fe8d0b8d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
